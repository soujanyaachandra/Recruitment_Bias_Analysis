{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxSiNxVvV3tt",
    "outputId": "ccac7196-6a3b-45dd-bc9f-d4ac249adb0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running WEAT for BERT\n",
      "WEAT Effect Size (Technical vs. Male): -0.19896414875984192\n",
      "WEAT Effect Size (Technical vs. Female): 0.19896414875984192\n",
      "WEAT Effect Size (Non-Technical vs. Male): -0.11526905000209808\n",
      "WEAT Effect Size (Non-Technical vs. Female): 0.11526905000209808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_word_embeddings(model, tokenizer, words):\n",
    "    return get_embeddings_batch(model, tokenizer, words)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=50):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.append([feature_names[idx] for idx in top_indices])\n",
    "    return keywords\n",
    "\n",
    "def create_word_sets_fast(model, tokenizer, keywords_list, top_n=100):\n",
    "    all_keywords = list(set(word for sublist in keywords_list for word in sublist))\n",
    "    embeddings = get_word_embeddings(model, tokenizer, all_keywords)\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "    # Assign clusters to technical and non-technical categories\n",
    "    cluster_0 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "    cluster_1 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 1]\n",
    "\n",
    "    # Heuristic: Assume the cluster with more domain-specific words is technical\n",
    "    technical_words, non_technical_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    return technical_words[:top_n], non_technical_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "resume_keywords = extract_keywords_fast(data['Resume'].tolist())\n",
    "job_desc_keywords = extract_keywords_fast(data['Job Description'].tolist())\n",
    "technical_words, non_technical_words = create_word_sets_fast(model, tokenizer, resume_keywords + job_desc_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    technical_embeddings = get_embeddings_batch(model, tokenizer, technical_words)\n",
    "    non_technical_embeddings = get_embeddings_batch(model, tokenizer, non_technical_words)\n",
    "    avg_male_embedding = np.mean(male_embeddings, axis=0)\n",
    "    avg_female_embedding = np.mean(female_embeddings, axis=0)\n",
    "    avg_technical_embedding = np.mean(technical_embeddings, axis=0)\n",
    "    avg_non_technical_embedding = np.mean(non_technical_embeddings, axis=0)\n",
    "    technical_male_effect_size = weat_effect_size_fast(avg_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    technical_female_effect_size = weat_effect_size_fast(avg_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_male_effect_size = weat_effect_size_fast(avg_non_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_female_effect_size = weat_effect_size_fast(avg_non_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    print(f\"WEAT Effect Size (Technical vs. Male): {technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Technical vs. Female): {technical_female_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Male): {non_technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Female): {non_technical_female_effect_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1Esv4RjZ2rM",
    "outputId": "a1526509-5313-49a5-cb3d-b3e0efba31ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Technical Words: ['harvard', 'stanford']\n",
      "Sample Non-Technical Words: ['structural', 'nutritional']\n",
      "Running WEAT for BERT\n",
      "WEAT Effect Size (Technical vs. Male): -0.3001048266887665\n",
      "WEAT Effect Size (Technical vs. Female): 0.3001048266887665\n",
      "WEAT Effect Size (Non-Technical vs. Male): -0.3287501037120819\n",
      "WEAT Effect Size (Non-Technical vs. Female): 0.3287501037120819\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_word_embeddings(model, tokenizer, words):\n",
    "    return get_embeddings_batch(model, tokenizer, words)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=50):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.append([feature_names[idx] for idx in top_indices])\n",
    "    return keywords\n",
    "\n",
    "def create_word_sets_fast(model, tokenizer, keywords_list, top_n=100):\n",
    "    all_keywords = list(set(word for sublist in keywords_list for word in sublist))\n",
    "    embeddings = get_word_embeddings(model, tokenizer, all_keywords)\n",
    "\n",
    "    # Reduce dimensionality using PCA for better clustering\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Apply DBSCAN clustering\n",
    "    clustering = DBSCAN(eps=0.5, min_samples=2, metric='euclidean').fit(reduced_embeddings)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    # Separate words based on clusters\n",
    "    cluster_0 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "    cluster_1 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 1]\n",
    "\n",
    "    # Assign clusters\n",
    "    technical_words, non_technical_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    print(\"Sample Technical Words:\", technical_words[:10])\n",
    "    print(\"Sample Non-Technical Words:\", non_technical_words[:10])\n",
    "\n",
    "    return technical_words[:top_n], non_technical_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "resume_keywords = extract_keywords_fast(data['Resume'].tolist())\n",
    "job_desc_keywords = extract_keywords_fast(data['Job Description'].tolist())\n",
    "technical_words, non_technical_words = create_word_sets_fast(model, tokenizer, resume_keywords + job_desc_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    technical_embeddings = get_embeddings_batch(model, tokenizer, technical_words)\n",
    "    non_technical_embeddings = get_embeddings_batch(model, tokenizer, non_technical_words)\n",
    "    avg_male_embedding = np.mean(male_embeddings, axis=0)\n",
    "    avg_female_embedding = np.mean(female_embeddings, axis=0)\n",
    "    avg_technical_embedding = np.mean(technical_embeddings, axis=0)\n",
    "    avg_non_technical_embedding = np.mean(non_technical_embeddings, axis=0)\n",
    "    technical_male_effect_size = weat_effect_size_fast(avg_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    technical_female_effect_size = weat_effect_size_fast(avg_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_male_effect_size = weat_effect_size_fast(avg_non_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_female_effect_size = weat_effect_size_fast(avg_non_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    print(f\"WEAT Effect Size (Technical vs. Male): {technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Technical vs. Female): {technical_female_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Male): {non_technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Female): {non_technical_female_effect_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIn1cO_8d1f2",
    "outputId": "a5011bbf-75a2-44bb-b6b6-83e5713e1a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: DBSCAN formed only one cluster. Falling back to K-Means.\n",
      "Cluster 0 Size: 578, Cluster 1 Size: 877\n",
      "Sample Cluster 0 Words: ['cisp', 'physiology', 'aligns', 'dba', 'architects', 'javascript', 'media', 'advanced', 'methodology', 'hypotheses']\n",
      "Sample Cluster 1 Words: ['adhere', 'solution', 'sales', 'abilities', 'think', 'excellent', 'ongoing', 'prescribe', 'hospital', 'engine']\n",
      "Final Technical Words: ['cisp', 'physiology', 'aligns', 'dba', 'architects', 'javascript', 'media', 'advanced', 'methodology', 'hypotheses']\n",
      "Final Non-Technical Words: ['adhere', 'solution', 'sales', 'abilities', 'think', 'excellent', 'ongoing', 'prescribe', 'hospital', 'engine']\n",
      "Running WEAT for BERT\n",
      "WEAT Effect Size (Technical vs. Male): -0.2007535994052887\n",
      "WEAT Effect Size (Technical vs. Female): 0.2007535994052887\n",
      "WEAT Effect Size (Non-Technical vs. Male): -0.1131492331624031\n",
      "WEAT Effect Size (Non-Technical vs. Female): 0.1131492331624031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_word_embeddings(model, tokenizer, words):\n",
    "    return get_embeddings_batch(model, tokenizer, words)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=50):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.append([feature_names[idx] for idx in top_indices])\n",
    "    return keywords\n",
    "\n",
    "def create_word_sets_fast(model, tokenizer, keywords_list, top_n=100):\n",
    "    all_keywords = list(set(word for sublist in keywords_list for word in sublist))\n",
    "    embeddings = get_word_embeddings(model, tokenizer, all_keywords)\n",
    "\n",
    "    # Reduce dimensionality using PCA for better clustering\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Apply DBSCAN clustering with cosine similarity\n",
    "    clustering = DBSCAN(eps=0.7, min_samples=2, metric='cosine').fit(reduced_embeddings)\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    # Separate words based on clusters\n",
    "    unique_labels = set(labels)\n",
    "    if len(unique_labels) < 2:\n",
    "        print(\"Warning: DBSCAN formed only one cluster. Falling back to K-Means.\")\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(reduced_embeddings)\n",
    "\n",
    "    cluster_0 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "    cluster_1 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 1]\n",
    "\n",
    "    print(f\"Cluster 0 Size: {len(cluster_0)}, Cluster 1 Size: {len(cluster_1)}\")\n",
    "    print(\"Sample Cluster 0 Words:\", cluster_0[:10])\n",
    "    print(\"Sample Cluster 1 Words:\", cluster_1[:10])\n",
    "\n",
    "    # Assign clusters based on size heuristic\n",
    "    technical_words, non_technical_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    print(\"Final Technical Words:\", technical_words[:10])\n",
    "    print(\"Final Non-Technical Words:\", non_technical_words[:10])\n",
    "\n",
    "    return technical_words[:top_n], non_technical_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "resume_keywords = extract_keywords_fast(data['Resume'].tolist())\n",
    "job_desc_keywords = extract_keywords_fast(data['Job Description'].tolist())\n",
    "technical_words, non_technical_words = create_word_sets_fast(model, tokenizer, resume_keywords + job_desc_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    technical_embeddings = get_embeddings_batch(model, tokenizer, technical_words)\n",
    "    non_technical_embeddings = get_embeddings_batch(model, tokenizer, non_technical_words)\n",
    "    avg_male_embedding = np.mean(male_embeddings, axis=0)\n",
    "    avg_female_embedding = np.mean(female_embeddings, axis=0)\n",
    "    avg_technical_embedding = np.mean(technical_embeddings, axis=0)\n",
    "    avg_non_technical_embedding = np.mean(non_technical_embeddings, axis=0)\n",
    "    technical_male_effect_size = weat_effect_size_fast(avg_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    technical_female_effect_size = weat_effect_size_fast(avg_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_male_effect_size = weat_effect_size_fast(avg_non_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_female_effect_size = weat_effect_size_fast(avg_non_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    print(f\"WEAT Effect Size (Technical vs. Male): {technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Technical vs. Female): {technical_female_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Male): {non_technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Female): {non_technical_female_effect_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518,
     "referenced_widgets": [
      "05f712a9d19841d0b71e998796ef82c9",
      "83387be9005c43cfa1431d447caee0e0",
      "5f8c38407be64fa293d6761820d1463c",
      "0ad5eae3048b407c8702e74a586fd634",
      "24963ae6bdde4cdaa7f3b0f0702ac3b5",
      "f70641650b2943f8bb75eeb8f22d1de2",
      "e452505cd76047c98280167ff4df5042",
      "daf5be5fcf814376ac241a8a51034ee0",
      "48415d80d3454d70bd6d93bb41a9e30c",
      "28909e1029224e1e84299047f16e9c98",
      "1972a685af754608bbb230970634f81c",
      "5f61ce562a46422eb40182f17a4901be",
      "a2503f521e5946079fcd60a8340cdc0f",
      "eada0b235e9b418181cdee95834915c4",
      "fb4d0e302e6c47a2a3c908bdbd6cdca5",
      "66f450c450e74bf890836f52fbb8423e",
      "2a9ced57e5724ad7ab803c41e2078fdb",
      "46644687371b4a44b54a6b2f9ce21e98",
      "52304399a6f5475bbe089cc7ae728c50",
      "9981cd2764374368bc9d6941824caff9",
      "1a66db8eee8644ed9bb019bb3b317835",
      "d3d45186120e4fbaac088d8fb5a5b6e6",
      "00ec3c25f8c94b1caf21d2a34c0585a3",
      "fdacad7fd5c44eac95d3da3ef9deb738",
      "6b503ef97bd84ec6bb4dabdcddd1af70",
      "4b04f917cab3498cb262894bf2c9c4dd",
      "182ca31893e7499398e0bcfd89df4610",
      "2c825f1f086249dab57a57e7f07a622d",
      "354721d8b73a4fdea16447c7f234d685",
      "088caf01b7704b0ab51b902c809e2695",
      "4aade3a569b647ef80f290f9b7725327",
      "a2c39b1aad0c437c8bcce2b6846d1de7",
      "e7aa0c3400484f91aeac2d85e1445ee3",
      "4eec17d2abc54f1a8760bcabb9d35964",
      "e47d7b1155ad4884a0beb1c702e887b1",
      "89d53ba8adf34548bf05c7adb8eaf2fc",
      "ad9e3bd3ab4447acba727dd04fc6ac2d",
      "c076a6c277064bc497a1e524f7608193",
      "9eefedb6b7f14eab9c6dff14f6685cbe",
      "2cf04a3f7f194112b704261d825e960d",
      "744d44593e674f3c8908169de1ea964c",
      "f31137f6f2394fd8998ef0a839823f1c",
      "4f1d04f75a914f6bbe860368f031bdbb",
      "5758c2b021ec40f0b2e5be4ae42967bb",
      "dc292536d2a040f1afb77fea64cf8787",
      "225c2d6ef52f47a8b75a9bc8090c3578",
      "8765d93e39f644b8b2b047fad1a8d332",
      "3f869eddd41843ddb6a8428445503ee9",
      "589651456ae0483690b5868cc3acaa81",
      "52b669793cea40e28a40d5af3ad53f9a",
      "cd6589d2e68b45eea6689a9cf17a8ffd",
      "1ac2feebf681477c92ff11148f05a9c3",
      "3054bf66ed7946d2a3cb4fc1f6adaa49",
      "91ef487e820648408fdbb39a8c9ad8d3",
      "8ac25d2546a44534a117e336c5f3cce6"
     ]
    },
    "id": "xGegbHXsoBsp",
    "outputId": "ff750606-73f9-4a5f-944d-c89d59548c55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f712a9d19841d0b71e998796ef82c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f61ce562a46422eb40182f17a4901be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ec3c25f8c94b1caf21d2a34c0585a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eec17d2abc54f1a8760bcabb9d35964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc292536d2a040f1afb77fea64cf8787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Size: 886, Cluster 1 Size: 568\n",
      "Sample Cluster 0 Words: ['workflows', 'improvement', 'mitigate', 'coach', 'cisp', 'communities', 'gsec', 'counseling', 'public', 'documentation']\n",
      "Sample Cluster 1 Words: ['planners', 'pastry', 'solving', 'target', 'meets', 'making', 'lives', 'producing', 'administering', 'response']\n",
      "Final Technical Words: ['planners', 'pastry', 'solving', 'target', 'meets', 'making', 'lives', 'producing', 'administering', 'response']\n",
      "Final Non-Technical Words: ['workflows', 'improvement', 'mitigate', 'coach', 'cisp', 'communities', 'gsec', 'counseling', 'public', 'documentation']\n",
      "Running WEAT for BERT\n",
      "WEAT Effect Size (Technical vs. Male): -0.13780327141284943\n",
      "WEAT Effect Size (Technical vs. Female): 0.13780327141284943\n",
      "WEAT Effect Size (Non-Technical vs. Male): -0.20972082018852234\n",
      "WEAT Effect Size (Non-Technical vs. Female): 0.20972082018852234\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_word_embeddings(model, tokenizer, words):\n",
    "    return get_embeddings_batch(model, tokenizer, words)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=50):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.append([feature_names[idx] for idx in top_indices if feature_names[idx] not in stop_words])\n",
    "    return keywords\n",
    "\n",
    "def create_word_sets_fast(model, tokenizer, keywords_list, top_n=100):\n",
    "    all_keywords = list(set(word for sublist in keywords_list for word in sublist if word not in stop_words))\n",
    "    embeddings = get_word_embeddings(model, tokenizer, all_keywords)\n",
    "\n",
    "    # Reduce dimensionality using PCA for better clustering\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Apply Hierarchical Clustering with correct metric parameter\n",
    "    clustering = AgglomerativeClustering(n_clusters=2, metric='euclidean', linkage='ward')\n",
    "    labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "    # Separate words based on clusters\n",
    "    cluster_0 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "    cluster_1 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 1]\n",
    "\n",
    "    print(f\"Cluster 0 Size: {len(cluster_0)}, Cluster 1 Size: {len(cluster_1)}\")\n",
    "    print(\"Sample Cluster 0 Words:\", cluster_0[:10])\n",
    "    print(\"Sample Cluster 1 Words:\", cluster_1[:10])\n",
    "\n",
    "    # Assign clusters based on size heuristic\n",
    "    technical_words, non_technical_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    print(\"Final Technical Words:\", technical_words[:10])\n",
    "    print(\"Final Non-Technical Words:\", non_technical_words[:10])\n",
    "\n",
    "    return technical_words[:top_n], non_technical_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "resume_keywords = extract_keywords_fast(data['Resume'].tolist())\n",
    "job_desc_keywords = extract_keywords_fast(data['Job Description'].tolist())\n",
    "technical_words, non_technical_words = create_word_sets_fast(model, tokenizer, resume_keywords + job_desc_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    technical_embeddings = get_embeddings_batch(model, tokenizer, technical_words)\n",
    "    non_technical_embeddings = get_embeddings_batch(model, tokenizer, non_technical_words)\n",
    "    avg_male_embedding = np.mean(male_embeddings, axis=0)\n",
    "    avg_female_embedding = np.mean(female_embeddings, axis=0)\n",
    "    avg_technical_embedding = np.mean(technical_embeddings, axis=0)\n",
    "    avg_non_technical_embedding = np.mean(non_technical_embeddings, axis=0)\n",
    "    technical_male_effect_size = weat_effect_size_fast(avg_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    technical_female_effect_size = weat_effect_size_fast(avg_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_male_effect_size = weat_effect_size_fast(avg_non_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_female_effect_size = weat_effect_size_fast(avg_non_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    print(f\"WEAT Effect Size (Technical vs. Male): {technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Technical vs. Female): {technical_female_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Male): {non_technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Female): {non_technical_female_effect_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnPxPvVCUeGR",
    "outputId": "15a0dc10-7f37-4daf-e2a1-78740f20ccad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 Size: 680, Cluster 1 Size: 774\n",
      "Sample Cluster 0 Words: ['progress', 'human', 'cbp', 'maximum', 'dmd', 'optimize', 'pedagogy', 'semrush', 'comprehensive', 'aviation']\n",
      "Sample Cluster 1 Words: ['learn', 'maintain', 'handler', 'responding', 'tested', 'launches', 'emergencies', 'google', 'sensors', 'reporting']\n",
      "Final Technical Words: ['human', 'cbp', 'maximum', 'dmd', 'optimize', 'pedagogy', 'semrush', 'comprehensive', 'aviation', 'weather']\n",
      "Final Non-Technical Words: ['progress', 'learn', 'maintain', 'handler', 'responding', 'tested', 'launches', 'emergencies', 'google', 'sensors']\n",
      "Running WEAT for BERT\n",
      "WEAT Effect Size (Technical vs. Male): -0.16136282682418823\n",
      "WEAT Effect Size (Technical vs. Female): 0.16136282682418823\n",
      "WEAT Effect Size (Non-Technical vs. Male): -0.1031954288482666\n",
      "WEAT Effect Size (Non-Technical vs. Female): 0.1031954288482666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_word_embeddings(model, tokenizer, words):\n",
    "    return get_embeddings_batch(model, tokenizer, words)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=150):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.append([feature_names[idx] for idx in top_indices if feature_names[idx] not in stop_words])\n",
    "    return keywords\n",
    "\n",
    "def refine_clusters(technical_words, non_technical_words, word_embeddings):\n",
    "    tech_mean = np.mean([word_embeddings[word] for word in technical_words], axis=0)\n",
    "    non_tech_mean = np.mean([word_embeddings[word] for word in non_technical_words], axis=0)\n",
    "\n",
    "    refined_technical = []\n",
    "    refined_non_technical = []\n",
    "\n",
    "    for word, embedding in word_embeddings.items():\n",
    "        if cosine(embedding, tech_mean) < cosine(embedding, non_tech_mean):\n",
    "            refined_technical.append(word)\n",
    "        else:\n",
    "            refined_non_technical.append(word)\n",
    "\n",
    "    return refined_technical, refined_non_technical\n",
    "\n",
    "def create_word_sets_fast(model, tokenizer, keywords_list, top_n=100):\n",
    "    all_keywords = list(set(word for sublist in keywords_list for word in sublist if word not in stop_words))\n",
    "    word_embeddings = {word: get_word_embeddings(model, tokenizer, [word])[0] for word in all_keywords}\n",
    "\n",
    "    # Reduce dimensionality using PCA for better clustering\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(list(word_embeddings.values()))\n",
    "\n",
    "    # Apply Hierarchical Clustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=2, metric='euclidean', linkage='ward')\n",
    "    labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "    # Separate words based on clusters\n",
    "    cluster_0 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "    cluster_1 = [all_keywords[i] for i in range(len(labels)) if labels[i] == 1]\n",
    "\n",
    "    print(f\"Cluster 0 Size: {len(cluster_0)}, Cluster 1 Size: {len(cluster_1)}\")\n",
    "    print(\"Sample Cluster 0 Words:\", cluster_0[:10])\n",
    "    print(\"Sample Cluster 1 Words:\", cluster_1[:10])\n",
    "\n",
    "    # Assign clusters based on size heuristic\n",
    "    technical_words, non_technical_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    # Refine clusters based on embedding similarity\n",
    "    technical_words, non_technical_words = refine_clusters(technical_words, non_technical_words, word_embeddings)\n",
    "\n",
    "    print(\"Final Technical Words:\", technical_words[:10])\n",
    "    print(\"Final Non-Technical Words:\", non_technical_words[:10])\n",
    "\n",
    "    return technical_words[:top_n], non_technical_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "resume_keywords = extract_keywords_fast(data['Resume'].tolist())\n",
    "job_desc_keywords = extract_keywords_fast(data['Job Description'].tolist())\n",
    "technical_words, non_technical_words = create_word_sets_fast(model, tokenizer, resume_keywords + job_desc_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    technical_embeddings = get_embeddings_batch(model, tokenizer, technical_words)\n",
    "    non_technical_embeddings = get_embeddings_batch(model, tokenizer, non_technical_words)\n",
    "    avg_male_embedding = np.mean(male_embeddings, axis=0)\n",
    "    avg_female_embedding = np.mean(female_embeddings, axis=0)\n",
    "    avg_technical_embedding = np.mean(technical_embeddings, axis=0)\n",
    "    avg_non_technical_embedding = np.mean(non_technical_embeddings, axis=0)\n",
    "    technical_male_effect_size = weat_effect_size_fast(avg_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    technical_female_effect_size = weat_effect_size_fast(avg_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_male_effect_size = weat_effect_size_fast(avg_non_technical_embedding, male_embeddings, female_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    non_technical_female_effect_size = weat_effect_size_fast(avg_non_technical_embedding, female_embeddings, male_embeddings, technical_embeddings, non_technical_embeddings)\n",
    "    print(f\"WEAT Effect Size (Technical vs. Male): {technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Technical vs. Female): {technical_female_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Male): {non_technical_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (Non-Technical vs. Female): {non_technical_female_effect_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC2SgrmjOOj9",
    "outputId": "6b952e82-59f2-47ed-fbfb-be2c51e41781"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Technical Words: ['roadmap', 'cbp', 'dmd', 'scrummaster', 'pedagogy', 'semrush', 'palliative', 'cbap', '13485', 'cfi', 'autocad', 'vts', 'cpce', 'xd', 'cism', 'scalability', 'fms', 'journeyman', 'tesol', 'chc']\n",
      "Final Non-Technical Words: ['pharmaceuticals', 'degree', 'psychologist', 'creation', 'private', 'owner', 'human', 'geographic', 'compliance', 'handler', 'design', 'service', 'ethical', 'medicine', 'equipment', 'illustrator', 'feedback', 'psychology', 'weather', 'google']\n",
      "Running WEAT for BERT\n",
      "WEAT Effect Size (STEM vs. Male): -0.02400081604719162\n",
      "WEAT Effect Size (STEM vs. Female): 0.02400081604719162\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative Clustering\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=1000):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.extend([feature_names[idx] for idx in top_indices if feature_names[idx] not in stop_words])\n",
    "    return list(set(keywords))  # Ensure unique keywords\n",
    "\n",
    "def create_stem_word_sets(model, tokenizer, stem_keywords, non_stem_keywords, top_n=100):\n",
    "    all_keywords = list(set(stem_keywords + non_stem_keywords))  # Flatten lists if needed\n",
    "    word_embeddings = {word: get_embeddings_batch(model, tokenizer, [word])[0] for word in all_keywords if isinstance(word, str) and word.strip()}\n",
    "\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(list(word_embeddings.values()))\n",
    "\n",
    "    clustering = AgglomerativeClustering(n_clusters=2, metric='euclidean', linkage='ward')\n",
    "    labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "    cluster_0 = [word for i, word in enumerate(all_keywords) if labels[i] == 0]\n",
    "    cluster_1 = [word for i, word in enumerate(all_keywords) if labels[i] == 1]\n",
    "\n",
    "    stem_words, non_stem_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "    print(\"Final Technical Words:\", stem_words[:20])\n",
    "    print(\"Final Non-Technical Words:\", non_stem_words[:20])\n",
    "    return stem_words[:top_n], non_stem_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "\n",
    "stem_jobs = [\"Software Engineer\", \"Machine Learning Engineer\", \"AI Researcher\", \"Robotics Engineer\", \"Mechanical Engineer\", \"Cloud Architect\", \"Cybersecurity Analyst\", \"Web Developer\", \"Database Administrator\", \"Data Analyst\", \"Research Scientist\", \"Environmental Scientist\", \"Biomedical Engineer\", \"Physician\", \"Pharmacist\", \"Dentist\", \"Veterinarian\", \"Nurse\", \"Civil Engineer\", \"Systems Analyst\", \"AI Specialist\", \"SEO Specialist\"]\n",
    "\n",
    "stem_resumes = data[data['Job Roles'].isin(stem_jobs)]['Resume'].tolist()\n",
    "non_stem_resumes = data[~data['Job Roles'].isin(stem_jobs)]['Resume'].tolist()\n",
    "\n",
    "stem_keywords = extract_keywords_fast(stem_resumes)\n",
    "non_stem_keywords = extract_keywords_fast(non_stem_resumes)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "stem_words, non_stem_words = create_stem_word_sets(model, tokenizer, stem_keywords, non_stem_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    stem_embeddings = get_embeddings_batch(model, tokenizer, stem_words)\n",
    "    non_stem_embeddings = get_embeddings_batch(model, tokenizer, non_stem_words)\n",
    "    avg_stem_embedding = np.mean(stem_embeddings, axis=0)\n",
    "    avg_non_stem_embedding = np.mean(non_stem_embeddings, axis=0)\n",
    "\n",
    "    stem_male_effect_size = weat_effect_size_fast(avg_stem_embedding, male_embeddings, female_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "    stem_female_effect_size = weat_effect_size_fast(avg_stem_embedding, female_embeddings, male_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "\n",
    "    print(f\"WEAT Effect Size (STEM vs. Male): {stem_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (STEM vs. Female): {stem_female_effect_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57dCVyA3WRNE",
    "outputId": "8e28f5bc-4b63-458d-b6c7-c445b5a1babc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running WEAT for BERT\n",
      "WEAT Effect Size (STEM vs. Male): -0.2138620913028717\n",
      "WEAT Effect Size (STEM vs. Female): 0.2138620913028717\n",
      "Top STEM Words: ['pharmaceuticals', 'roadmap', 'psychologist', 'scrummaster', 'medicine', 'pedagogy', 'equipment', 'psychology', 'weather', 'auditing', 'facebook', 'goal', 'certifications', 'leadership', 'gphr', 'palliative', 'transportation', 'health', 'hygiene', 'autocad']\n",
      "Top Non-STEM Words: ['degree', 'creation', 'private', 'owner', 'human', 'geographic', 'cbp', 'compliance', 'handler', 'design', 'dmd', 'service', 'ethical', 'illustrator', 'feedback', 'semrush', 'google', 'insertion', 'cross', 'academy']\n",
      "WEAT Effect Size (STEM vs. Female): 0.2138620913028717\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=50):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.extend([feature_names[idx] for idx in top_indices if feature_names[idx] not in stop_words])\n",
    "    return list(set(keywords))  # Ensure unique keywords\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def create_stem_word_sets(model, tokenizer, stem_keywords, non_stem_keywords, top_n=100):\n",
    "    all_keywords = list(set(stem_keywords + non_stem_keywords))  # Flatten lists if needed\n",
    "    word_embeddings = {word: get_embeddings_batch(model, tokenizer, [word])[0] for word in all_keywords if isinstance(word, str) and word.strip()}\n",
    "\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(list(word_embeddings.values()))\n",
    "\n",
    "    clustering = KMeans(n_clusters=2, random_state=42)\n",
    "    labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "    cluster_0 = [word for i, word in enumerate(all_keywords) if labels[i] == 0]\n",
    "    cluster_1 = [word for i, word in enumerate(all_keywords) if labels[i] == 1]\n",
    "\n",
    "    stem_words, non_stem_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    return stem_words[:top_n], non_stem_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "\n",
    "stem_jobs = [\"Software Engineer\", \"Machine Learning Engineer\", \"AI Researcher\", \"Robotics Engineer\", \"Mechanical Engineer\", \"Cloud Architect\", \"Cybersecurity Analyst\", \"Web Developer\", \"Database Administrator\", \"Data Analyst\", \"Research Scientist\", \"Environmental Scientist\", \"Biomedical Engineer\", \"Physician\", \"Pharmacist\", \"Dentist\", \"Veterinarian\", \"Nurse\", \"Civil Engineer\", \"Systems Analyst\", \"AI Specialist\", \"SEO Specialist\"]\n",
    "\n",
    "stem_resumes = data[data['Job Roles'].isin(stem_jobs)]['Resume'].tolist()\n",
    "non_stem_resumes = data[~data['Job Roles'].isin(stem_jobs)]['Resume'].tolist()\n",
    "\n",
    "stem_keywords = extract_keywords_fast(stem_resumes)\n",
    "non_stem_keywords = extract_keywords_fast(non_stem_resumes)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "stem_words, non_stem_words = create_stem_word_sets(model, tokenizer, stem_keywords, non_stem_keywords)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    stem_embeddings = get_embeddings_batch(model, tokenizer, stem_words)\n",
    "    non_stem_embeddings = get_embeddings_batch(model, tokenizer, non_stem_words)\n",
    "    avg_stem_embedding = np.mean(stem_embeddings, axis=0)\n",
    "    avg_non_stem_embedding = np.mean(non_stem_embeddings, axis=0)\n",
    "\n",
    "    stem_male_effect_size = weat_effect_size_fast(avg_stem_embedding, male_embeddings, female_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "    stem_female_effect_size = weat_effect_size_fast(avg_stem_embedding, female_embeddings, male_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "\n",
    "    print(f\"WEAT Effect Size (STEM vs. Male): {stem_male_effect_size}\")\n",
    "    print(f\"WEAT Effect Size (STEM vs. Female): {stem_female_effect_size}\")\n",
    "    print(\"Top STEM Words:\", stem_words[:20])\n",
    "    print(\"Top Non-STEM Words:\", non_stem_words[:20])\n",
    "    print(f\"WEAT Effect Size (STEM vs. Female): {stem_female_effect_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "id": "ry6f6viFXI7c",
    "outputId": "d0bc6b9b-d68d-4f6d-ce7a-9c7f85d1f773"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bcba34ebd411>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mnon_stem_resumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Job Roles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Resume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mstem_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keywords_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem_resumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mnon_stem_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keywords_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_stem_resumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bcba34ebd411>\u001b[0m in \u001b[0;36mextract_keywords_fast\u001b[0;34m(texts, num_keywords)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfiltered_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtagged_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtagged_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NNS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JJ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Keep only nouns and adjectives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mfiltered_keywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load, lang)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_conf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tagdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mload_from_json\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Automatically find path to the tagger if location is not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"taggers/averaged_perceptron_tagger_{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTAGGER_JSONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def cosine_similarity_matrix(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return np.dot(a_norm, b_norm.T)\n",
    "\n",
    "def weat_effect_size_fast(w, a, b, s_x, s_y):\n",
    "    w_a = np.mean(cosine_similarity_matrix(w.reshape(1, -1), a))\n",
    "    w_b = np.mean(cosine_similarity_matrix(w.reshape(1, -1), b))\n",
    "    s_all = np.vstack((s_x, s_y))\n",
    "    return (w_a - w_b) / np.std(cosine_similarity_matrix(w.reshape(1, -1), s_all))\n",
    "\n",
    "def get_embeddings_batch(model, tokenizer, text_list, batch_size=32):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def extract_keywords_fast(texts, num_keywords=50):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    keywords = []\n",
    "    for row in tfidf_matrix:\n",
    "        top_indices = np.argsort(row.toarray()[0])[-num_keywords:]\n",
    "        keywords.extend([feature_names[idx] for idx in top_indices if feature_names[idx] not in stop_words])\n",
    "        filtered_keywords = []\n",
    "    for word in set(keywords):\n",
    "        tagged_word = pos_tag([word])\n",
    "        if tagged_word[0][1] in ['NN', 'NNS', 'JJ']:  # Keep only nouns and adjectives\n",
    "            filtered_keywords.append(word)\n",
    "    return filtered_keywords  # Ensure unique keywords\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def create_stem_word_sets(model, tokenizer, stem_keywords, non_stem_keywords, top_n=100):\n",
    "    all_keywords = list(set(stem_keywords + non_stem_keywords))  # Flatten lists if needed\n",
    "    word_embeddings = {word: get_embeddings_batch(model, tokenizer, [word])[0] for word in all_keywords if isinstance(word, str) and word.strip()}\n",
    "\n",
    "    pca = PCA(n_components=10)\n",
    "    reduced_embeddings = pca.fit_transform(list(word_embeddings.values()))\n",
    "\n",
    "    clustering = KMeans(n_clusters=2, random_state=42)\n",
    "    labels = clustering.fit_predict(reduced_embeddings)\n",
    "\n",
    "    cluster_0 = [word for i, word in enumerate(all_keywords) if labels[i] == 0]\n",
    "    cluster_1 = [word for i, word in enumerate(all_keywords) if labels[i] == 1]\n",
    "\n",
    "    stem_words, non_stem_words = (cluster_0, cluster_1) if len(cluster_0) < len(cluster_1) else (cluster_1, cluster_0)\n",
    "\n",
    "    return stem_words[:top_n], non_stem_words[:top_n]\n",
    "\n",
    "male_terms = [\"man\", \"male\", \"he\", \"him\"]\n",
    "female_terms = [\"woman\", \"female\", \"she\", \"her\"]\n",
    "\n",
    "models = {\"BERT\": (\"bert-base-uncased\", AutoModel)}\n",
    "\n",
    "data = pd.read_csv(\"/content/job_applicant_dataset_trial4.csv\")\n",
    "\n",
    "stem_jobs = [\"Software Engineer\", \"Machine Learning Engineer\", \"AI Researcher\", \"Robotics Engineer\", \"Mechanical Engineer\", \"Cloud Architect\", \"Cybersecurity Analyst\", \"Web Developer\", \"Database Administrator\", \"Data Analyst\", \"Research Scientist\", \"Environmental Scientist\", \"Biomedical Engineer\", \"Physician\", \"Pharmacist\", \"Dentist\", \"Veterinarian\", \"Nurse\", \"Civil Engineer\", \"Systems Analyst\", \"AI Specialist\", \"SEO Specialist\"]\n",
    "\n",
    "stem_resumes = data[data['Job Roles'].isin(stem_jobs)]['Resume'].tolist()\n",
    "non_stem_resumes = data[~data['Job Roles'].isin(stem_jobs)]['Resume'].tolist()\n",
    "\n",
    "stem_keywords = extract_keywords_fast(stem_resumes)\n",
    "non_stem_keywords = extract_keywords_fast(non_stem_resumes)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "stem_words, non_stem_words = create_stem_word_sets(model, tokenizer, stem_keywords, non_stem_keywords)\n",
    "\n",
    "import random\n",
    "\n",
    "def bootstrap_weat_test(model, tokenizer, male_terms, female_terms, stem_words, non_stem_words, num_samples=100):\n",
    "    effect_sizes = []\n",
    "    for _ in range(num_samples):\n",
    "        random.shuffle(stem_words)\n",
    "        random.shuffle(non_stem_words)\n",
    "        stem_sample = stem_words[:50]\n",
    "        non_stem_sample = non_stem_words[:50]\n",
    "\n",
    "        stem_embeddings = get_embeddings_batch(model, tokenizer, stem_sample)\n",
    "        non_stem_embeddings = get_embeddings_batch(model, tokenizer, non_stem_sample)\n",
    "        avg_stem_embedding = np.mean(stem_embeddings, axis=0)\n",
    "        avg_non_stem_embedding = np.mean(non_stem_embeddings, axis=0)\n",
    "\n",
    "        effect_size = weat_effect_size_fast(avg_stem_embedding, male_embeddings, female_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "        effect_sizes.append(effect_size)\n",
    "    return np.mean(effect_sizes), np.std(effect_sizes)\n",
    "\n",
    "for model_name, (model_path, model_class) in models.items():\n",
    "    print(f\"Running WEAT for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = model_class.from_pretrained(model_path)\n",
    "    male_embeddings = get_embeddings_batch(model, tokenizer, male_terms)\n",
    "    female_embeddings = get_embeddings_batch(model, tokenizer, female_terms)\n",
    "    stem_embeddings = get_embeddings_batch(model, tokenizer, stem_words)\n",
    "    non_stem_embeddings = get_embeddings_batch(model, tokenizer, non_stem_words)\n",
    "    avg_stem_embedding = np.mean(stem_embeddings, axis=0)\n",
    "    avg_non_stem_embedding = np.mean(non_stem_embeddings, axis=0)\n",
    "\n",
    "    stem_male_effect_size = weat_effect_size_fast(avg_stem_embedding, male_embeddings, female_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "    stem_female_effect_size = weat_effect_size_fast(avg_stem_embedding, female_embeddings, male_embeddings, stem_embeddings, non_stem_embeddings)\n",
    "\n",
    "    mean_effect, std_effect = bootstrap_weat_test(model, tokenizer, male_terms, female_terms, stem_words, non_stem_words)\n",
    "    print(f\"WEAT Effect Size (STEM vs. Male): {stem_male_effect_size} (±{std_effect})\")\n",
    "    print(f\"WEAT Effect Size (STEM vs. Female): {stem_female_effect_size}\")\n",
    "    print(\"Top STEM Words:\", stem_words[:20])\n",
    "    print(\"Top Non-STEM Words:\", non_stem_words[:20])\n",
    "    print(f\"WEAT Effect Size (STEM vs. Female): {stem_female_effect_size}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ec3c25f8c94b1caf21d2a34c0585a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdacad7fd5c44eac95d3da3ef9deb738",
       "IPY_MODEL_6b503ef97bd84ec6bb4dabdcddd1af70",
       "IPY_MODEL_4b04f917cab3498cb262894bf2c9c4dd"
      ],
      "layout": "IPY_MODEL_182ca31893e7499398e0bcfd89df4610"
     }
    },
    "05f712a9d19841d0b71e998796ef82c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83387be9005c43cfa1431d447caee0e0",
       "IPY_MODEL_5f8c38407be64fa293d6761820d1463c",
       "IPY_MODEL_0ad5eae3048b407c8702e74a586fd634"
      ],
      "layout": "IPY_MODEL_24963ae6bdde4cdaa7f3b0f0702ac3b5"
     }
    },
    "088caf01b7704b0ab51b902c809e2695": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad5eae3048b407c8702e74a586fd634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28909e1029224e1e84299047f16e9c98",
      "placeholder": "​",
      "style": "IPY_MODEL_1972a685af754608bbb230970634f81c",
      "value": " 48.0/48.0 [00:00&lt;00:00, 2.73kB/s]"
     }
    },
    "182ca31893e7499398e0bcfd89df4610": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1972a685af754608bbb230970634f81c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a66db8eee8644ed9bb019bb3b317835": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ac2feebf681477c92ff11148f05a9c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "225c2d6ef52f47a8b75a9bc8090c3578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52b669793cea40e28a40d5af3ad53f9a",
      "placeholder": "​",
      "style": "IPY_MODEL_cd6589d2e68b45eea6689a9cf17a8ffd",
      "value": "model.safetensors: 100%"
     }
    },
    "24963ae6bdde4cdaa7f3b0f0702ac3b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28909e1029224e1e84299047f16e9c98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a9ced57e5724ad7ab803c41e2078fdb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c825f1f086249dab57a57e7f07a622d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cf04a3f7f194112b704261d825e960d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3054bf66ed7946d2a3cb4fc1f6adaa49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "354721d8b73a4fdea16447c7f234d685": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f869eddd41843ddb6a8428445503ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91ef487e820648408fdbb39a8c9ad8d3",
      "placeholder": "​",
      "style": "IPY_MODEL_8ac25d2546a44534a117e336c5f3cce6",
      "value": " 440M/440M [00:02&lt;00:00, 172MB/s]"
     }
    },
    "46644687371b4a44b54a6b2f9ce21e98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48415d80d3454d70bd6d93bb41a9e30c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4aade3a569b647ef80f290f9b7725327": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b04f917cab3498cb262894bf2c9c4dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2c39b1aad0c437c8bcce2b6846d1de7",
      "placeholder": "​",
      "style": "IPY_MODEL_e7aa0c3400484f91aeac2d85e1445ee3",
      "value": " 232k/232k [00:00&lt;00:00, 4.33MB/s]"
     }
    },
    "4eec17d2abc54f1a8760bcabb9d35964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e47d7b1155ad4884a0beb1c702e887b1",
       "IPY_MODEL_89d53ba8adf34548bf05c7adb8eaf2fc",
       "IPY_MODEL_ad9e3bd3ab4447acba727dd04fc6ac2d"
      ],
      "layout": "IPY_MODEL_c076a6c277064bc497a1e524f7608193"
     }
    },
    "4f1d04f75a914f6bbe860368f031bdbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52304399a6f5475bbe089cc7ae728c50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52b669793cea40e28a40d5af3ad53f9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5758c2b021ec40f0b2e5be4ae42967bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "589651456ae0483690b5868cc3acaa81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f61ce562a46422eb40182f17a4901be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2503f521e5946079fcd60a8340cdc0f",
       "IPY_MODEL_eada0b235e9b418181cdee95834915c4",
       "IPY_MODEL_fb4d0e302e6c47a2a3c908bdbd6cdca5"
      ],
      "layout": "IPY_MODEL_66f450c450e74bf890836f52fbb8423e"
     }
    },
    "5f8c38407be64fa293d6761820d1463c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daf5be5fcf814376ac241a8a51034ee0",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48415d80d3454d70bd6d93bb41a9e30c",
      "value": 48
     }
    },
    "66f450c450e74bf890836f52fbb8423e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b503ef97bd84ec6bb4dabdcddd1af70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_088caf01b7704b0ab51b902c809e2695",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4aade3a569b647ef80f290f9b7725327",
      "value": 231508
     }
    },
    "744d44593e674f3c8908169de1ea964c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83387be9005c43cfa1431d447caee0e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f70641650b2943f8bb75eeb8f22d1de2",
      "placeholder": "​",
      "style": "IPY_MODEL_e452505cd76047c98280167ff4df5042",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "8765d93e39f644b8b2b047fad1a8d332": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ac2feebf681477c92ff11148f05a9c3",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3054bf66ed7946d2a3cb4fc1f6adaa49",
      "value": 440449768
     }
    },
    "89d53ba8adf34548bf05c7adb8eaf2fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_744d44593e674f3c8908169de1ea964c",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f31137f6f2394fd8998ef0a839823f1c",
      "value": 466062
     }
    },
    "8ac25d2546a44534a117e336c5f3cce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91ef487e820648408fdbb39a8c9ad8d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9981cd2764374368bc9d6941824caff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9eefedb6b7f14eab9c6dff14f6685cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2503f521e5946079fcd60a8340cdc0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a9ced57e5724ad7ab803c41e2078fdb",
      "placeholder": "​",
      "style": "IPY_MODEL_46644687371b4a44b54a6b2f9ce21e98",
      "value": "config.json: 100%"
     }
    },
    "a2c39b1aad0c437c8bcce2b6846d1de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9e3bd3ab4447acba727dd04fc6ac2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f1d04f75a914f6bbe860368f031bdbb",
      "placeholder": "​",
      "style": "IPY_MODEL_5758c2b021ec40f0b2e5be4ae42967bb",
      "value": " 466k/466k [00:00&lt;00:00, 7.84MB/s]"
     }
    },
    "c076a6c277064bc497a1e524f7608193": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd6589d2e68b45eea6689a9cf17a8ffd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3d45186120e4fbaac088d8fb5a5b6e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "daf5be5fcf814376ac241a8a51034ee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc292536d2a040f1afb77fea64cf8787": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_225c2d6ef52f47a8b75a9bc8090c3578",
       "IPY_MODEL_8765d93e39f644b8b2b047fad1a8d332",
       "IPY_MODEL_3f869eddd41843ddb6a8428445503ee9"
      ],
      "layout": "IPY_MODEL_589651456ae0483690b5868cc3acaa81"
     }
    },
    "e452505cd76047c98280167ff4df5042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e47d7b1155ad4884a0beb1c702e887b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9eefedb6b7f14eab9c6dff14f6685cbe",
      "placeholder": "​",
      "style": "IPY_MODEL_2cf04a3f7f194112b704261d825e960d",
      "value": "tokenizer.json: 100%"
     }
    },
    "e7aa0c3400484f91aeac2d85e1445ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eada0b235e9b418181cdee95834915c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52304399a6f5475bbe089cc7ae728c50",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9981cd2764374368bc9d6941824caff9",
      "value": 570
     }
    },
    "f31137f6f2394fd8998ef0a839823f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f70641650b2943f8bb75eeb8f22d1de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb4d0e302e6c47a2a3c908bdbd6cdca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a66db8eee8644ed9bb019bb3b317835",
      "placeholder": "​",
      "style": "IPY_MODEL_d3d45186120e4fbaac088d8fb5a5b6e6",
      "value": " 570/570 [00:00&lt;00:00, 32.3kB/s]"
     }
    },
    "fdacad7fd5c44eac95d3da3ef9deb738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c825f1f086249dab57a57e7f07a622d",
      "placeholder": "​",
      "style": "IPY_MODEL_354721d8b73a4fdea16447c7f234d685",
      "value": "vocab.txt: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
