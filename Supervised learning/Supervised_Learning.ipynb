{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88270b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"job_applicant_dataset_trial4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_dedup.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(include=['object'])\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a47802",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=cat.drop(columns=['Resume','Job Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b6fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ef9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9470eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Job Applicant Name: Frequency Encoding\n",
    "applicant_name_freq = cat[\"Job Applicant Name\"].value_counts()\n",
    "cat[\"Job Applicant Name\"] = cat[\"Job Applicant Name\"].map(applicant_name_freq)\n",
    "\n",
    "# Gender: One-Hot Encoding\n",
    "cat = pd.get_dummies(cat, columns=[\"Gender\"], dtype=int)\n",
    "\n",
    "# Race: Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "cat[\"Race\"] = label_encoder.fit_transform(cat[\"Race\"])\n",
    "\n",
    "# Ethnicity: Frequency Encoding\n",
    "ethnicity_freq = cat[\"Ethnicity\"].value_counts()\n",
    "cat[\"Ethnicity\"] = cat[\"Ethnicity\"].map(ethnicity_freq)\n",
    "\n",
    "# Job Roles: Frequency Encoding\n",
    "job_roles_freq = cat[\"Job Roles\"].value_counts()\n",
    "cat[\"Job Roles\"] = cat[\"Job Roles\"].map(job_roles_freq)\n",
    "\n",
    "print(\"Encoded DataFrame:\")\n",
    "print(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb49623",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cat.columns: \n",
    "    print(f\"\\nValue counts for column '{column}':\")\n",
    "    print(cat[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "numeric_columns = ['Age'] \n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Apply scaling only to the 'Age' column\n",
    "num_array = scaler.fit_transform(num[numeric_columns])\n",
    "\n",
    "# Create a DataFrame with the scaled 'Age' column and the unchanged 'Best Match' column\n",
    "num_df = num.copy()\n",
    "num_df['Age'] = num_array\n",
    "\n",
    "print(num_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = cat.columns\n",
    "scaler = RobustScaler()\n",
    "cat_array = scaler.fit_transform(cat)\n",
    "cat_df = pd.DataFrame(cat_array, columns=cat_columns, index=cat.index)\n",
    "print(cat_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98929ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=pd.concat([num_df, cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603586e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868eaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Apply Yeo-Johnson Transformation (which works on both positive and negative values)\n",
    "columns_to_transform = ['Job Applicant Name', 'Job Roles']\n",
    "\n",
    "# Instantiate the PowerTransformer with Yeo-Johnson\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "# Apply transformation to the specified columns\n",
    "main_df[columns_to_transform] = pt.fit_transform(main_df[columns_to_transform])\n",
    "\n",
    "# Check skewness after transformation\n",
    "print(main_df.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe392ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(15, 10))  # Set the figure size\n",
    "sns.heatmap(main_df.corr(),annot=True)\n",
    "plt.show()\n",
    "# sns.heatmap(main_df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# target_column = 'Best Match'\n",
    "# feature_columns = main_df.columns.difference([target_column])  # Exclude target column\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# # Apply RobustScaler only to feature columns\n",
    "# main_df_scaled = main_df.copy()\n",
    "# main_df_scaled[feature_columns] = scaler.fit_transform(main_df[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45174ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming main_df is your DataFrame and 'Best Match' is the target column\n",
    "\n",
    "# Step 1: Prepare the data (X - Features, y - Target)\n",
    "X = main_df.drop(columns=['Best Match'])  # Drop the target column 'Best Match'\n",
    "y = main_df['Best Match']  # Target variable (binary)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 3: Print the training and testing datasets\n",
    "print(\"Training Features (X_train):\")\n",
    "print(X_train)  # Print first few rows of the training features\n",
    "print(\"\\nTesting Features (X_test):\")\n",
    "print(X_test)  # Print first few rows of the testing features\n",
    "\n",
    "print(\"\\nTraining Target (y_train):\")\n",
    "print(y_train)  # Print first few rows of the training target variable\n",
    "print(\"\\nTesting Target (y_test):\")\n",
    "print(y_test)  # Print first few rows of the testing target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 4: Train the Logistic Regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Step 4: Train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # 100 trees in the forest\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
